"""
ì±„íŒ… API ë¼ìš°íŠ¸

LangGraph ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.

ì—”ë“œí¬ì¸íŠ¸:
    POST /chat/          - ì±„íŒ… ë©”ì‹œì§€ ì „ì†¡
"""

from typing import AsyncGenerator

from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from langchain_core.messages import AIMessage, AIMessageChunk, BaseMessage, HumanMessage
from loguru import logger

from app.schemas.chat import ChatRequest, ChatResponse, StreamEvent
from app.graph import get_lumi_graph

router = APIRouter()

# In-Memory ì„¸ì…˜ ì €ì¥ì†Œ (ì„œë²„ ì¬ì‹œì‘ ì‹œ ì´ˆê¸°í™”ë¨)
SESSION_STORE: dict[str, list[BaseMessage]] = {}


@router.post("/", response_model=ChatResponse)
async def chat(request: ChatRequest) -> ChatResponse:
    """
    ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸

    ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ LangGraph ì—ì´ì „íŠ¸ë¡œ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        request: ì±„íŒ… ìš”ì²­ (message, session_id, user_id)

    Returns:
        ChatResponse: ë£¨ë¯¸ì˜ ì‘ë‹µ

    Raises:
        HTTPException: ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜ ì‹œ

    Example:
        ```bash
        curl -X POST "http://localhost:8000/api/v1/chat/" \\
            -H "Content-Type: application/json" \\
            -d '{"message": "ì˜¤ëŠ˜ ë°©ì†¡ ì–¸ì œì•¼?", "session_id": "user123"}'
        ```
    """
    logger.info(f"ğŸ“© ì±„íŒ… ìš”ì²­: session={request.session_id}")

    try:
        # TODO 1: LangGraph ê·¸ë˜í”„ ê°€ì ¸ì˜¤ê¸°
        graph = get_lumi_graph()

        # TODO 2: ì´ˆê¸° ìƒíƒœ ìƒì„±
        initial_state = {
            "messages": [HumanMessage(content=request.message)],
            "intent": None,
            "retrieved_docs": [],
            "tool_name": None,
            "tool_args": None,
            "tool_result": None,
            "session_id": request.session_id,
            "user_id": request.user_id,
        }

        # TODO 3: ê·¸ë˜í”„ ì‹¤í–‰ (ë¹„ë™ê¸°)
        final_state = await graph.ainvoke(initial_state)

        # TODO 4: ìµœì¢… ì‘ë‹µ ì¶”ì¶œ
        messages = final_state["messages"]
        if not messages:
            raise ValueError("ì‘ë‹µ ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        ai_response = messages[-1].content
        tool_used = final_state.get("tool_name")

        logger.info(f"ğŸ“¤ ì‘ë‹µ ì „ì†¡: tool_used={tool_used}")
        
        # TODO 5: ChatResponse ë°˜í™˜
        return ChatResponse(
            message=ai_response,
            tool_used=tool_used,
            cached=False,
        )

    except Exception as e:
        logger.error(f"ì±„íŒ… ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
        )

# SSE ìŠ¤íŠ¸ë¦¬ë° - Helper í•¨ìˆ˜
async def stream_with_status(
    message: str,
    session_id: str,
    user_id: str | None = None,
) -> AsyncGenerator[tuple[str | None, str | None, str | None, str | None], None]:
    """
    ë…¸ë“œ ìƒíƒœ + í† í° ìŠ¤íŠ¸ë¦¬ë° ê²°í•©

    ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•˜ë©´ì„œ í† í°ë„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
    Gradio UIì—ì„œ "ìƒê° ì¤‘...", "Tool ì‹¤í–‰ ì¤‘..." í‘œì‹œì— ì‚¬ìš©ë©ë‹ˆë‹¤.

    í•µì‹¬: stream_mode=["updates", "messages"]
        - updates: ë…¸ë“œ ì™„ë£Œ ì‹œ ì´ë²¤íŠ¸ â†’ ì§„í–‰ ìƒíƒœ í‘œì‹œ
        - messages: í† í° ë‹¨ìœ„ ì´ë²¤íŠ¸ â†’ ChatGPTì²˜ëŸ¼ ê¸€ì ìŠ¤íŠ¸ë¦¬ë°

    Yields:
        tuple[status, token, final_response, tool_used]:
            - (status, None, None, None): ì§„í–‰ ìƒí™© ë©”ì‹œì§€
            - (None, token, None, None): ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ í† í°
            - (None, None, final_response, tool_used): ìµœì¢… ì‘ë‹µ
    """
    graph = get_lumi_graph()

    # ì„¸ì…˜ì—ì„œ ì´ì „ ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    session_id = session_id or "default"
    history = SESSION_STORE.get(session_id, [])
    new_message = HumanMessage(content=message)

    # ì´ˆê¸° ìƒíƒœ ìƒì„±
    initial_state = {
        "messages": history + [new_message],
        "intent": None,
        "retrieved_docs": [],
        "tool_name": None,
        "tool_args": None,
        "tool_result": None,
        "session_id": session_id,
        "user_id": user_id,
    }

    logger.debug(f"ğŸ“œ [StreamWithStatus] ì„¸ì…˜ íˆìŠ¤í† ë¦¬: {len(history)}ê°œ ë©”ì‹œì§€")

    final_response = ""
    final_tool_name = None
    current_node = None

    # TODO 1: ë…¸ë“œë³„ ìƒíƒœ ë©”ì‹œì§€ ì •ì˜
    node_status = {
        "router": "ë£¨ë¯¸ ìƒê° ì¤‘ ...",
        "rag": "ì •ë³´ ê²€ìƒ‰ ì¤‘ ...",
        "tool": "ë„êµ¬ ì‹¤í–‰ ì¤‘ ...",
        "response": "ì‘ë‹µ ìƒì„± ì¤‘ ...",
    }

    # TODO 2: ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ ì„¤ì •
    async for mode, event in graph.astream(initial_state, stream_mode=["updates", "messages"]):  # type: ignore # stream_mode ìˆ˜ì •!
        # TODO 3: ë…¸ë“œ ìŠ¤íŠ¸ë¦¬ë° (mode == "updates")
        if mode == "updates":
            for node_name, node_output in event.items():
                # ì—¬ê¸°ì— êµ¬í˜„í•˜ì„¸ìš”!
                if node_name != current_node and node_name in node_status:
                    current_node = node_name
                    yield (node_status[node_name], None, None, None)
                    logger.debug(f"[stream_with_status] ë…¸ë“œ ì§„ì…: {node_name}")
                    
                if node_name =="tool" and node_output:
                    final_tool_name = node_output.get("tool_name")
                    
        # TODO 4: í† í° ìŠ¤íŠ¸ë¦¬ë° (mode == "messages")
        elif mode == "messages":    
            msg, meta = event
            # ì—¬ê¸°ì— êµ¬í˜„í•˜ì„¸ìš”!
            node_name = meta.get("langgraph_node", "")
            
            if node_name != "response":
                continue
            if isinstance(msg, AIMessageChunk):
                token = msg.content or ""
                if token:
                    final_response += token
                    yield (None, token, None, None)

    # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ì €ì¥
    if final_response:
        if session_id not in SESSION_STORE:
            SESSION_STORE[session_id] = []
        SESSION_STORE[session_id].append(new_message)
        SESSION_STORE[session_id].append(AIMessage(content=final_response))
        logger.debug(f"ğŸ’¾ [StreamWithStatus] ì„¸ì…˜ ì €ì¥: {session_id}")

    # ë§ˆì§€ë§‰ì— ìµœì¢… ì‘ë‹µ yield : status, token, final_response, final_tool_name
    yield (None, None, final_response, final_tool_name)


# SSE ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸
@router.post("/stream")
async def chat_stream(request: ChatRequest) -> StreamingResponse:
    """
    SSE ë…¸ë“œ + í† í° ìŠ¤íŠ¸ë¦¬ë° ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸

    stream_with_statusë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¸ë“œ ìƒíƒœ(thinking)ì™€ í† í°ì„ ë™ì‹œì— ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.

    SSE ì´ë²¤íŠ¸ íƒ€ì…:
        - thinking: ë…¸ë“œ ì§„í–‰ ìƒí™© ("ğŸ”€ ë£¨ë¯¸ ìƒê° ì¤‘...")
        - token: LLM í† í° (ê¸€ì ë‹¨ìœ„)
        - response: ìµœì¢… ì‘ë‹µ
        - error: ì—ëŸ¬
        - done: ìŠ¤íŠ¸ë¦¬ë° ì¢…ë£Œ

    Example:
        ```bash
        curl -N -X POST "http://localhost:8000/api/v1/chat/stream" \\
            -H "Content-Type: application/json" \\
            -d '{"message": "ì˜¤ëŠ˜ ë°©ì†¡ ì–¸ì œì•¼?", "session_id": "user123"}'
        ```
    """
    logger.info(f"ğŸ“© [Stream] ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­: session={request.session_id}")

    async def generate() -> AsyncGenerator[str, None]:
        """SSE ì´ë²¤íŠ¸ ìƒì„±ê¸° - ë…¸ë“œ ìƒíƒœ + í† í° ìŠ¤íŠ¸ë¦¬ë°"""
        try:
            async for status, token, final, tool_used in stream_with_status(
                request.message,
                request.session_id,
                request.user_id,
            ):
                # TODO 5: ì´ë²¤íŠ¸ íƒ€ì…ë³„(thinking, token, response) SSE ì „ì†¡
                if status:
                    yield StreamEvent(type="thinking", content=status).to_sse()
                    
                    
                    
                if token:
                    yield StreamEvent(type="token", content=token).to_sse()
                if final:
                    yield StreamEvent(type="response", content=final, tool_used=tool_used).to_sse()

            # TODO 6: ì™„ë£Œ ì´ë²¤íŠ¸ ì „ì†¡
            yield StreamEvent(type="done").to_sse()
            logger.info(f"âœ… [Stream] ì™„ë£Œ: session={request.session_id}")


        except Exception as e:
            logger.error(f"âŒ [Stream] ì˜¤ë¥˜: {e}")
            yield StreamEvent(type="error", error=str(e)).to_sse()
            yield StreamEvent(type="done").to_sse()

    # TODO 7: StreamingResponse ë°˜í™˜
    return StreamingResponse(
        generate(),
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-buffering": "no",
            "Content-Type": "text/event-stream",
        }
    )  